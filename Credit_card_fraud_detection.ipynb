{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "  # **Credit Card Fraud Detection using Scikit-Learn and Snap ML**\n"
      ],
      "metadata": {
        "id": "r97vIDwO38Ad"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VA7QUtc5rwu"
      },
      "outputs": [],
      "source": [
        "%pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4cBWIrh5rwy"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/mlg-ulb/creditcardfraud\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GL-3Fyee5rwz"
      },
      "outputs": [],
      "source": [
        "%pip install snapml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6lULqsY5rwz"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1Y3YREO5rwz"
      },
      "source": [
        "# Dataset Analysis\n",
        "In this section you will read the dataset in a Pandas dataframe and visualize its content. You will also look at some data statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dhLDKdO5rw1"
      },
      "outputs": [],
      "source": [
        "#read the data\n",
        "raw_data = pd.read_csv('./creditcardfraud/creditcard.csv')\n",
        "print(\"There are \" + str(len(raw_data)) + \" observations in the credit card fraud dataset.\")\n",
        "print(\"There are \" + str(len(raw_data.columns)) + \" variables in the dataset.\")\n",
        "\n",
        "raw_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eWWm3IE5rw1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "raw_data = pd.read_csv('./creditcardfraud/creditcard.csv')\n",
        "print(\"There are\"+str(len(raw_data))+\"observations in the credit card fraud dataset.\")\n",
        "print(\"There are\"+str(len(raw_data.columns))+\"variables in the data set\")\n",
        "raw_data.head()\n",
        "raw_data.hist(column=[\"Time\",\"V1\"],bins=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqaOu7OV5rw2"
      },
      "source": [
        "  In practice, a financial institution may have access to a much larger dataset of transactions. To simulate such a case, we will inflate the original one 10 times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9psEZAyR5rw2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have a CSV file named 'creditcard.csv' in the 'creditcardfraud' folder\n",
        "file_path = './creditcardfraud/creditcard.csv'\n",
        "raw_data = pd.read_csv(file_path)\n",
        "\n",
        "n_replicas = 10\n",
        "big_raw_data = pd.DataFrame(np.repeat(raw_data.values, n_replicas, axis=0), columns=raw_data.columns)\n",
        "print(\"There are \" + str(len(big_raw_data)) + \" observations in the dataset\")\n",
        "print(\"There are \" + str(len(big_raw_data.columns)) + \" columns in the dataset \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqp25vyw5rw3"
      },
      "source": [
        "labels: This line extracts the unique values in the 'Class' column of the 'big_raw_data' DataFrame. These unique values represent the distinct classes in your dataset.\n",
        "sizes: This line calculates the count of each unique class in the 'Class' column using the value_counts() function. It retrieves the values (counts) associated with each unique class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDk-aKLA5rw3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'big_raw_data' is a DataFrame with a 'Class' column\n",
        "labels = big_raw_data['Class'].unique()\n",
        "sizes = big_raw_data['Class'].value_counts().values\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.pie(sizes, labels=labels, autopct='%1.3f%%')\n",
        "ax.set_title('Target Variable Value Counts')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi90fkFc5rw4"
      },
      "outputs": [],
      "source": [
        "file_path = './creditcardfraud/creditcard.csv'\n",
        "big_raw_data = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "# we provide our solution here\n",
        "plt.hist(big_raw_data.Amount.values, 6, histtype='bar', facecolor='g')\n",
        "plt.show()\n",
        "\n",
        "print(\"Minimum amount value is \", np.min(big_raw_data.Amount.values))\n",
        "print(\"Maximum amount value is \", np.max(big_raw_data.Amount.values))\n",
        "print(\"90% of the transactions have an amount less or equal than \", np.percentile(raw_data.Amount.values, 90))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9HquQJ25rw4"
      },
      "source": [
        "# Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfOtsPHC5rw4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "big_raw_data.iloc[:, 1:30] = StandardScaler().fit_transform(big_raw_data.iloc[:, 1:30])\n",
        "data_matrix = big_raw_data.values\n",
        "x = data_matrix[:, 1:30]\n",
        "y = data_matrix[:, 30]\n",
        "x = normalize(x, norm='l1')  # Use the normalize function from sklearn.preprocessing\n",
        "print(\"x.shape=\", x.shape, \",y.shape=\", y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lig4IkHR5rw5"
      },
      "outputs": [],
      "source": [
        "%pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBmAmTkv5rw5"
      },
      "source": [
        "# train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye23JFxB5rw5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "print(\"x_train=\", x_train.shape)\n",
        "print(\"x_test=\", x_test.shape)\n",
        "print(\"y_train=\", y_train.shape)\n",
        "print(\"y_test=\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div id=\"dt_sklearn\">\n",
        "    <h2>Build a Decision Tree Classifier model with Scikit-Learn</h2>\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "kF49yB7p7Wb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import time\n",
        "\n",
        "# Assuming you have loaded or created your dataset and defined y_train\n",
        "# Example: x_train, y_train = load_or_create_regression_dataset()\n",
        "\n",
        "w_train = compute_sample_weight('balanced', y_train)\n",
        "\n",
        "sklearn_dt = DecisionTreeRegressor(max_depth=4, random_state=35)\n",
        "\n",
        "t0 = time.time()\n",
        "sklearn_dt.fit(x_train, y_train, sample_weight=w_train)\n",
        "sklearn_time = time.time() - t0\n",
        "print(\"[Scikit-Learn] Training time (s):  {0:.5f}\".format(sklearn_time))\n"
      ],
      "metadata": {
        "id": "uRui4cr47G_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div id=\"dt_snapml\">\n",
        "    <h2>Build a Decision Tree Classifier model with Snap ML</h2>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "Gvwl02qB9Eww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have computed your sample weights and defined x_train, y_train\n",
        "# Example: w_train = compute_sample_weight('balanced', y_train)\n",
        "\n",
        "# Import the Decision Tree Regressor Model from Snap ML\n",
        "from snapml import DecisionTreeRegressor\n",
        "\n",
        "# Snap ML offers multi-threaded CPU/GPU training of decision trees, unlike scikit-learn\n",
        "\n",
        "# Uncomment the line below if you have a GPU and want to use it\n",
        "# snapml_dt = DecisionTreeRegressor(max_depth=4, random_state=45, use_gpu=True, n_jobs=4)\n",
        "\n",
        "# Use the line below for CPU training\n",
        "snapml_dt = DecisionTreeRegressor(max_depth=4, random_state=45, n_jobs=4)\n",
        "\n",
        "# Train a Decision Tree Regressor model using Snap ML\n",
        "t0 = time.time()\n",
        "snapml_dt.fit(x_train, y_train, sample_weight=w_train)\n",
        "snapml_time = time.time() - t0\n",
        "print(\"[Snap ML] Training time (s):  {0:.5f}\".format(snapml_time))\n"
      ],
      "metadata": {
        "id": "q4XUaTGr9LfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div id=\"dt_sklearn_snapml\">\n",
        "    <h2>Evaluate the Scikit-Learn and Snap ML Decision Tree Classifier Models</h2>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "mwruwolJO2r2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from snapml import DecisionTreeRegressor\n",
        "snapml_dt = DecisionTreeRegressor(max_depth=5 , random_state=45,n_jobs=4)\n",
        "\n",
        "t0 = time.time()\n",
        "snapml_dt.fit(x_train,y_train,sample_weight=w_train)\n",
        "snapml_time = time.time() - t0\n",
        "print(\"[Snapml]training time(s): {0:.3F}\".format(snapml_time))"
      ],
      "metadata": {
        "id": "tTgZieCLPMdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div id=\"svm_sklearn\">\n",
        "    <h2>Build a Support Vector Machine model with Scikit-Learn</h2>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "zGx1b8KkRj-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the linear Support Vector Machine (SVM) model for regression from Scikit-Learn\n",
        "from sklearn.svm import LinearSVR\n",
        "import time\n",
        "\n",
        "# Assuming there is a mismatch in the number of samples, slice y_train to match x_train\n",
        "y_train = y_train[:199364]\n",
        "\n",
        "# Flatten y_train to make it a 1-dimensional array\n",
        "y_train = y_train.ravel()\n",
        "\n",
        "# instantiate a scikit-learn SVM regression model\n",
        "# for reproducible output across multiple function calls, set random_state to a given integer value\n",
        "sklearn_svm = LinearSVR(random_state=31, loss=\"epsilon_insensitive\", fit_intercept=False)\n",
        "\n",
        "# train a linear Support Vector Machine regression model using Scikit-Learn\n",
        "t0 = time.time()\n",
        "sklearn_svm.fit(x_train, y_train)\n",
        "sklearn_time = time.time() - t0\n",
        "print(\"[Scikit-Learn] Training time (s):  {0:.5f}\".format(sklearn_time))\n"
      ],
      "metadata": {
        "id": "rxzNiI2PpqRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div id=\"svm_snap\">\n",
        "    <h2>Build a Support Vector Machine model with Snap ML</h2>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "ipnBeYJ4rpPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the Support Vector Machine model (SVM) from Snap ML\n",
        "from snapml import SupportVectorMachine\n",
        "import time\n",
        "\n",
        "# in contrast to scikit-learn's LinearSVC, Snap ML offers multi-threaded CPU/GPU training of SVMs\n",
        "# to use the GPU, set the use_gpu parameter to True\n",
        "# snapml_svm = SupportVectorMachine(class_weight='balanced', random_state=25, use_gpu=True, fit_intercept=False)\n",
        "\n",
        "# to set the number of threads used at training time, one needs to set the n_jobs parameter\n",
        "snapml_svm = SupportVectorMachine(class_weight='balanced', random_state=25, n_jobs=4, fit_intercept=False)\n",
        "# print(snapml_svm.get_params())\n",
        "\n",
        "# train an SVM model using Snap ML\n",
        "t0 = time.time()\n",
        "model = snapml_svm.fit(x_train, y_train)\n",
        "snapml_time = time.time() - t0\n",
        "print(\"[Snap ML] Training time (s):  {0:.2f}\".format(snapml_time))"
      ],
      "metadata": {
        "id": "4Qw8dJXzm14P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div id=\"svm_sklearn_snap\">\n",
        "    <h2>Evaluate the Scikit-Learn and Snap ML Support Vector Machine Models</h2>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "U1XvmA9sruaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the Snap ML vs Scikit-Learn training speedup\n",
        "training_speedup = sklearn_time / snapml_time\n",
        "print('[Support Vector Machine] Snap ML vs. Scikit-Learn training speedup : {0:.2f}x '.format(training_speedup))\n",
        "\n",
        "# run inference using the Scikit-Learn model\n",
        "# get the confidence scores for the test samples\n",
        "sklearn_pred = sklearn_svm.predict(x_test)\n",
        "\n",
        "# evaluate accuracy on the test set\n",
        "acc_sklearn = roc_auc_score(y_test, sklearn_pred)\n",
        "print(\"[Scikit-Learn] ROC-AUC score:   {0:.3f}\".format(acc_sklearn))\n",
        "\n",
        "# run inference using the Snap ML model\n",
        "# get the confidence scores for the test samples\n",
        "snapml_pred = snapml_svm.decision_function(x_test)\n",
        "\n",
        "# evaluate accuracy on the test set\n",
        "acc_snapml = roc_auc_score(y_test, snapml_pred)\n",
        "print(\"[Snap ML] ROC-AUC score:   {0:.3f}\".format(acc_snapml))\n"
      ],
      "metadata": {
        "id": "-yYYpt69rlV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Author"
      ],
      "metadata": {
        "id": "XWwnLZq_3h9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Muizz.**"
      ],
      "metadata": {
        "id": "sC8g1MDA3ltS"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}